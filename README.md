# genie-in-the-bottle
As of November 2025, leading labs in Artificial Intelligence are in an arms race. Whoever gets to build AGI the first wins big. At the same time, AI also happens to be the most powerful and consequential invention humanity ever made. How come? Because no other tool has the ability to process information and make its own independent decisions, including the decision to improve itself or to eliminate factors it considers as hindrances.

There are risks that emerge out of AI research that can affect civilisation in enormous proportions - think at the scale of a world war, the 2008 financial crisis, or the Covid pandemic. And these are conservative estimates. At it's worst, AI could extinguish human civilisation and all other life on earth. Specifically, there are two classes of risk that emerge here:

1. A bad actor using AI maliciously - a nation-state using AI to attack another nation's energy grid, central healthcare system etc

2. AI itself becoming misaligned with general wellbeing of humanity. It doesn't have to be of 'I hate all humans' kind but simply 'I am building this hundred story building and don't care about the fate of all insects inhabiting the construction site'.

Collectively, we are not sufficiently alarmed by these developments. This is partly due to the fact that so much else is competing for our attention. News developments are scattered and probably not as sexy as news about the party tricks latest AI models can pull off.

This repository tries to solve this problem. It will collect all relevant news and developments, focus them into consumable chunks of information, and post on social media.
